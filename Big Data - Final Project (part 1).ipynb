{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08a2b6f-705c-4dba-a1e8-b5a262b36207",
   "metadata": {},
   "source": [
    "### <u>**COMP-548DL**</u>\n",
    "### <u>**Big Data Management and Processing**</u>\n",
    "### <u>**Semester Project**</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c97a097-8d4a-42ca-8454-e00c276c7ad3",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d78b7a2-4549-4e6e-96f1-081b4f0401cb",
   "metadata": {},
   "source": [
    "#### <u>**Part 1:**</u> \n",
    "#### This notebook contains the code used for uploading the data on Firestore in document format.\n",
    "#### A few queries are performed for experimentation, but then we transform the data into a JSON file in order to continue with the main approach.\n",
    "#### (Utilizing PySpark, uploading the data on GCS and provisioning a Dataproc cluster for the rest of the analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b8062cc-299f-4034-9f77-d53c02e50ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d70c056e-687f-4a88-af4e-74ea5b85283a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_APPLICATION_CREDENTIALS=C:\\Users\\ska_p\\OneDrive\\Desktop\\MSc Data Science\\Fall Semester 2024-25\\Big Data Management and Processing\\Final Project\\big-data-final-project-445611-3749e103c9e3.json\n"
     ]
    }
   ],
   "source": [
    " %env GOOGLE_APPLICATION_CREDENTIALS=C:\\Users\\ska_p\\OneDrive\\Desktop\\MSc Data Science\\Fall Semester 2024-25\\Big Data Management and Processing\\Final Project\\big-data-final-project-445611-3749e103c9e3.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde60537-6aa1-4301-b095-16a4f7cc8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Google Firestore\n",
    "cred = credentials.Certificate(\"C:/Users/ska_p/OneDrive/Desktop/MSc Data Science/Fall Semester 2024-25/Big Data Management and Processing/Final Project/big-data-final-project-445611-3749e103c9e3.json\")\n",
    "firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "# Creating a Firestore collection name\n",
    "collection_name = \"crime_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0bfabe-fc04-40df-ac65-00d96c04261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our dataset \n",
    "file_path = \"london_crime.csv\"  \n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e935eaa7-0805-4026-80f6-1371aeccb8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function for uploading the data in batches\n",
    "# Calling the function separately will help us tackle any issues in a timely and clean manner\n",
    "def upload_to_firestore(batch_size=499):\n",
    "    total_rows = len(data)\n",
    "    print(f\"Uploading {total_rows} rows to Firestore...\")\n",
    "\n",
    "    for start_idx in range(0, total_rows, batch_size):\n",
    "        batch = db.batch()\n",
    "        end_idx = min(start_idx + batch_size, total_rows)\n",
    "        print(f\"Uploading rows {start_idx} to {end_idx}...\")\n",
    "        \n",
    "        # Prepare documents for the batch\n",
    "        for _, row in data.iloc[start_idx:end_idx].iterrows():\n",
    "            doc_ref = db.collection(collection_name).document()\n",
    "            doc_data = {\n",
    "                \"lsoa_code\": row[\"lsoa_code\"],\n",
    "                \"borough\": row[\"borough\"],\n",
    "                \"major_category\": row[\"major_category\"],\n",
    "                \"minor_category\": row[\"minor_category\"],\n",
    "                \"value\": int(row[\"value\"]),\n",
    "                \"year\": int(row[\"year\"]),\n",
    "                \"month\": int(row[\"month\"]),\n",
    "            }\n",
    "            batch.set(doc_ref, doc_data)\n",
    "\n",
    "        # Commit the batch\n",
    "        batch.commit()\n",
    "\n",
    "    # Just a little reassurance...!    \n",
    "    print(\"Data upload complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655475c0-7a6a-46a7-a207-eac602c7a10e",
   "metadata": {},
   "source": [
    "#### Now we call the function to finish the upload. It is a very time-consuming process, but it obviously has to be executed only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0c2f7e2-7c24-4cc1-83df-ddc31d7df33d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 13490604 rows to Firestore...\n",
      "Uploading rows 0 to 499...\n",
      "Uploading rows 499 to 998...\n",
      
      "Uploading rows 13489966 to 13490465...\n",
      "Uploading rows 13490465 to 13490604...\n",
      "Data upload complete!\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "upload_to_firestore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a451b6-1d1b-4cf3-b4f5-4a3982af9ccd",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8795a16-109e-440e-a414-2209533bfeed",
   "metadata": {},
   "source": [
    "#### Let's perform a few queries to test the connection and that everything has been uploaded properly.\n",
    "#### We will limit the query replies in order to avoid potential issues emerging from the vast data volume on Firestore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b170413-1bcc-486b-9b8f-03b67a4dac50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: 0000pqVKxcVDaXRNeOap, Data: {'major_category': 'Criminal Damage', 'year': 2009, 'value': 0, 'lsoa_code': 'E01001111', 'borough': 'Croydon', 'month': 3, 'minor_category': 'Criminal Damage To Other Building'}\n"
     ]
    }
   ],
   "source": [
    "# Test Firestore connection by fetching the first document of the collection\n",
    "# We can verify the accuracy of the answer by simultaneously checking the firestore documents from the cloud\n",
    "collection_name = \"crime_data\"\n",
    "query = db.collection(collection_name).limit(1).stream()\n",
    "\n",
    "for doc in query:\n",
    "    print(f\"Document ID: {doc.id}, Data: {doc.to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "954aaef5-38e8-4aae-a43a-25131dddf7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in 'crime_data': 100000\n"
     ]
    }
   ],
   "source": [
    "# Count total documents in the collection\n",
    "# We limit this query to the first 100.000 documents to avoid computational power issues\n",
    "collection_name = \"crime_data\"\n",
    "docs = db.collection(collection_name).limit(100000).stream()\n",
    "doc_count = sum(1 for _ in docs)\n",
    "print(f\"Total documents in '{collection_name}': {doc_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac41973c-0e33-4a11-9a9f-e80cd5b573f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime records for borough 'Croydon':\n",
      "Document ID: 0000pqVKxcVDaXRNeOap, Data: {'major_category': 'Criminal Damage', 'year': 2009, 'value': 0, 'lsoa_code': 'E01001111', 'borough': 'Croydon', 'month': 3, 'minor_category': 'Criminal Damage To Other Building'}\n",
      "Document ID: 000AWa1pptq1ZvATBsPM, Data: {'major_category': 'Theft and Handling', 'year': 2015, 'value': 0, 'lsoa_code': 'E01001138', 'borough': 'Croydon', 'month': 11, 'minor_category': 'Handling Stolen Goods'}\n",
      "Document ID: 000DZCX3lSJXiYy4hyhA, Data: {'major_category': 'Robbery', 'year': 2015, 'value': 0, 'lsoa_code': 'E01000997', 'borough': 'Croydon', 'month': 7, 'minor_category': 'Personal Property'}\n",
      "Document ID: 000sSzwjQB2BuTKS1wDR, Data: {'major_category': 'Theft and Handling', 'year': 2010, 'value': 2, 'lsoa_code': 'E01001125', 'borough': 'Croydon', 'month': 8, 'minor_category': 'Theft From Shops'}\n",
      "Document ID: 0016uKFb4oAPegGKv79O, Data: {'major_category': 'Criminal Damage', 'year': 2016, 'value': 0, 'lsoa_code': 'E01000995', 'borough': 'Croydon', 'month': 10, 'minor_category': 'Other Criminal Damage'}\n",
      "Document ID: 001PFsv6qG6yFqv0v7bq, Data: {'major_category': 'Theft and Handling', 'year': 2012, 'value': 0, 'lsoa_code': 'E01001115', 'borough': 'Croydon', 'month': 1, 'minor_category': 'Motor Vehicle Interference & Tampering'}\n",
      "Document ID: 001kP0whKZgJKz20fuGG, Data: {'major_category': 'Theft and Handling', 'year': 2011, 'value': 0, 'lsoa_code': 'E01001194', 'borough': 'Croydon', 'month': 11, 'minor_category': 'Handling Stolen Goods'}\n",
      "Document ID: 001oB3nrzMiLpXu3iVdM, Data: {'major_category': 'Burglary', 'year': 2008, 'value': 1, 'lsoa_code': 'E01000982', 'borough': 'Croydon', 'month': 3, 'minor_category': 'Burglary in a Dwelling'}\n",
      "Document ID: 0023wnoJQw61TyE0fU9l, Data: {'major_category': 'Violence Against the Person', 'year': 2011, 'value': 1, 'lsoa_code': 'E01000990', 'borough': 'Croydon', 'month': 12, 'minor_category': 'Common Assault'}\n",
      "Document ID: 002k00WV7Ex7ck7r7PKs, Data: {'major_category': 'Violence Against the Person', 'year': 2010, 'value': 1, 'lsoa_code': 'E01001185', 'borough': 'Croydon', 'month': 3, 'minor_category': 'Assault with Injury'}\n"
     ]
    }
   ],
   "source": [
    "# Query for a specific borough\n",
    "# Again this is limited to the first 10 entries for simplicity reasons\n",
    "borough = \"Croydon\"\n",
    "query = db.collection(collection_name).where(\"borough\", \"==\", borough).limit(10).stream()\n",
    "\n",
    "print(f\"Crime records for borough '{borough}':\")\n",
    "for doc in query:\n",
    "    print(f\"Document ID: {doc.id}, Data: {doc.to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edef6dec-cba9-4bbc-9547-d1d4ac385b5c",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a189881a-6bd7-4346-a66e-18393bb28686",
   "metadata": {},
   "source": [
    "#### Queries in Firestore are working fine, but we will use a different approach to continue from now on.\n",
    "#### To end this notebook, we transform the dataset to JSON format, for uploading to a Dataproc bucket and continuing from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695c047c-b618-4816-b35d-5ef9e462f5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CSVtoJSON\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "223403bd-7f68-4693-8219-f29cd2cedcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------------------+-----+----+-----+\n",
      "|lsoa_code|             borough|      major_category|      minor_category|value|year|month|\n",
      "+---------+--------------------+--------------------+--------------------+-----+----+-----+\n",
      "|E01001116|             Croydon|            Burglary|Burglary in Other...|    0|2016|   11|\n",
      "|E01001646|           Greenwich|Violence Against ...|      Other violence|    0|2016|   11|\n",
      "|E01000677|             Bromley|Violence Against ...|      Other violence|    0|2015|    5|\n",
      "|E01003774|           Redbridge|            Burglary|Burglary in Other...|    0|2016|    3|\n",
      "|E01004563|          Wandsworth|             Robbery|   Personal Property|    0|2008|    6|\n",
      "|E01001320|              Ealing|  Theft and Handling|         Other Theft|    0|2012|    5|\n",
      "|E01001342|              Ealing|Violence Against ...|    Offensive Weapon|    0|2010|    7|\n",
      "|E01002633|            Hounslow|             Robbery|   Personal Property|    0|2013|    4|\n",
      "|E01003496|              Newham|     Criminal Damage|Criminal Damage T...|    0|2013|    9|\n",
      "|E01004177|              Sutton|  Theft and Handling|Theft/Taking of P...|    1|2016|    8|\n",
      "|E01001985|            Haringey|  Theft and Handling|Motor Vehicle Int...|    0|2013|   12|\n",
      "|E01003076|             Lambeth|Violence Against ...|      Other violence|    0|2015|    4|\n",
      "|E01003852|Richmond upon Thames|             Robbery|   Personal Property|    0|2014|    1|\n",
      "|E01004547|          Wandsworth|Violence Against ...|    Offensive Weapon|    0|2011|   10|\n",
      "|E01002398|          Hillingdon|  Theft and Handling|Theft/Taking Of M...|    0|2016|    2|\n",
      "|E01002358|            Havering|Violence Against ...|        Wounding/GBH|    0|2012|    2|\n",
      "|E01000086|Barking and Dagenham|  Theft and Handling|  Other Theft Person|    1|2009|    5|\n",
      "|E01003708|           Redbridge|Violence Against ...|      Common Assault|    0|2009|    6|\n",
      "|E01002945|Kingston upon Thames|  Theft and Handling|    Theft From Shops|    0|2016|   11|\n",
      "|E01004195|              Sutton|               Drugs| Possession Of Drugs|    0|2009|   10|\n",
      "+---------+--------------------+--------------------+--------------------+-----+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to our CSV file\n",
    "csv_file_path = \"london_crime.csv\"  \n",
    "\n",
    "# Load the CSV file\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8c0f9d-2a0f-44ec-b029-22fb3562f78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file saved at london_crime_json.json\n"
     ]
    }
   ],
   "source": [
    "# Path to save the JSON file\n",
    "json_file_path = \"london_crime_json.json\" \n",
    "\n",
    "# Save as JSON\n",
    "df.write.json(json_file_path)\n",
    "\n",
    "print(f\"JSON file saved at {json_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0797d81-5530-4ad8-8cf8-c1ab528a0d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
